{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3Q-d5IjPFWY"
      },
      "source": [
        "# Constraint-Guided Decoding for Small Language Models\n",
        "\n",
        "**Author:** Nolan W. Platt  \n",
        "**Project:** Lightweight Neurosymbolic Approach for SLMs\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xMpmv-iPFWZ"
      },
      "source": [
        "## Setup and Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1TT9VHOkPFWZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e19a2c0-26db-421b-fff4-ab332a1ee5b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.4/59.4 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.3/29.3 MB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# install required packages\n",
        "!pip install -q transformers accelerate bitsandbytes z3-solver torch sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4R1F8nFWPFWZ",
        "outputId": "09dafc30-8c66-4b97-a8db-13ea988d0930"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version: 2.9.0+cu126\n",
            "CUDA available: True\n",
            "GPU: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "from z3 import *\n",
        "import re\n",
        "from typing import List, Dict, Tuple, Set, Optional\n",
        "from dataclasses import dataclass\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "import time\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZHMN_ynPFWa"
      },
      "source": [
        "## Z3-Based Constraint Checker\n",
        "\n",
        "Implementation of the constraint engine with:\n",
        "1. Arithmetic constraint checking\n",
        "2. Logical consistency verification\n",
        "3. Variable tracking and extraction\n",
        "4. Constraint caching for efficiency"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "vdyQBplVPFWa"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class Constraint:\n",
        "    \"\"\"Represents a logical constraint\"\"\"\n",
        "    constraint_type: str  # 'arithmetic', 'logical', 'syntax'\n",
        "    expression: str\n",
        "    variables: Set[str]\n",
        "    z3_formula: Optional[Any] = None\n",
        "\n",
        "class ConstraintChecker:\n",
        "    \"\"\"Z3-based constraint verification engine\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.constraint_cache = {}\n",
        "\n",
        "    def clear(self):\n",
        "        \"\"\"Reset solver state\"\"\"\n",
        "        self.constraint_cache = {}\n",
        "\n",
        "    def extract_arithmetic_statements(self, text: str) -> List[Dict]:\n",
        "        \"\"\"\n",
        "        Extract arithmetic statements from text\n",
        "        Examples: \"x = 5\", \"y = 10\", \"x + y = 15\"\n",
        "        \"\"\"\n",
        "        statements = []\n",
        "\n",
        "        # Pattern: variable = number (but not part of an expression)\n",
        "        # using word boundaries and negative lookahead/lookbehind to avoid matching inside expressions\n",
        "        simple_pattern = r'(?<![+\\-*/])\\s*([a-zA-Z])\\s*=\\s*(\\d+(?:\\.\\d+)?)\\s*(?![+\\-*/])'\n",
        "\n",
        "        for match in re.finditer(simple_pattern, text):\n",
        "            var_name = match.group(1)\n",
        "            value = match.group(2)\n",
        "\n",
        "            # Skip if this looks like it's part of a larger expression\n",
        "            start = match.start()\n",
        "            if start > 0 and text[start-1] in '+-*/':\n",
        "                continue\n",
        "\n",
        "            statements.append({\n",
        "                'variable': var_name,\n",
        "                'value': float(value),\n",
        "                'full_text': match.group(0)\n",
        "            })\n",
        "\n",
        "        return statements\n",
        "\n",
        "    def check_arithmetic_consistency(self, text: str) -> Tuple[bool, List[str]]:\n",
        "        \"\"\"\n",
        "        Check if all arithmetic statements in text are consistent\n",
        "        Returns: (is_consistent, list_of_violations)\n",
        "        \"\"\"\n",
        "        cache_key = hash(text)\n",
        "        if cache_key in self.constraint_cache:\n",
        "            return self.constraint_cache[cache_key]\n",
        "\n",
        "        statements = self.extract_arithmetic_statements(text)\n",
        "        if not statements:\n",
        "            result = (True, [])\n",
        "            self.constraint_cache[cache_key] = result\n",
        "            return result\n",
        "\n",
        "        # build variable assignments\n",
        "        var_assignments = {}\n",
        "        violations = []\n",
        "\n",
        "        for stmt in statements:\n",
        "            var_name = stmt['variable']\n",
        "            value = stmt['value']\n",
        "\n",
        "            if var_name in var_assignments:\n",
        "                # check if this contradicts previous assignment\n",
        "                if abs(var_assignments[var_name] - value) > 0.001:\n",
        "                    violations.append(\n",
        "                        f\"Contradiction: {var_name} = {var_assignments[var_name]} \"\n",
        "                        f\"but later {var_name} = {value}\"\n",
        "                    )\n",
        "            else:\n",
        "                var_assignments[var_name] = value\n",
        "\n",
        "        #  check expressions like \"x + y = 15\"\n",
        "        expr_pattern = r'([a-zA-Z_]\\w*)\\s*\\+\\s*([a-zA-Z_]\\w*)\\s*=\\s*(\\d+(?:\\.\\d+)?)'\n",
        "        for match in re.finditer(expr_pattern, text):\n",
        "            var1 = match.group(1)\n",
        "            var2 = match.group(2)\n",
        "            expected = float(match.group(3))\n",
        "\n",
        "            if var1 in var_assignments and var2 in var_assignments:\n",
        "                actual = var_assignments[var1] + var_assignments[var2]\n",
        "                if abs(actual - expected) > 0.001:\n",
        "                    violations.append(\n",
        "                        f\"Arithmetic error: {var1} + {var2} should be {actual} \"\n",
        "                        f\"but text claims {expected}\"\n",
        "                    )\n",
        "\n",
        "        # check multiplication like \"2x = 10\"\n",
        "        mult_pattern = r'(\\d+)\\s*\\*?\\s*([a-zA-Z_]\\w*)\\s*=\\s*(\\d+(?:\\.\\d+)?)'\n",
        "        for match in re.finditer(mult_pattern, text):\n",
        "            multiplier = float(match.group(1))\n",
        "            var_name = match.group(2)\n",
        "            expected = float(match.group(3))\n",
        "\n",
        "            if var_name in var_assignments:\n",
        "                actual = multiplier * var_assignments[var_name]\n",
        "                if abs(actual - expected) > 0.001:\n",
        "                    violations.append(\n",
        "                        f\"Arithmetic error: {multiplier}*{var_name} should be {actual} \"\n",
        "                        f\"but text claims {expected}\"\n",
        "                    )\n",
        "\n",
        "        is_consistent = len(violations) == 0\n",
        "        result_tuple = (is_consistent, violations)\n",
        "        self.constraint_cache[cache_key] = result_tuple\n",
        "        return result_tuple\n",
        "\n",
        "    def check_logical_consistency(self, text: str) -> Tuple[bool, List[str]]:\n",
        "        \"\"\"\n",
        "        Check for logical contradictions\n",
        "        \"\"\"\n",
        "        violations = []\n",
        "\n",
        "        # true/false statements regex patterns\n",
        "        positive_pattern = r'([A-Z]\\w*)\\s+is\\s+(true|correct)'\n",
        "        negative_pattern = r'([A-Z]\\w*)\\s+is\\s+(false|incorrect|not\\s+true)'\n",
        "\n",
        "        positive_matches = [(m.group(1).lower(), m.group(0)) for m in re.finditer(positive_pattern, text, re.IGNORECASE)]\n",
        "        negative_matches = [(m.group(1).lower(), m.group(0)) for m in re.finditer(negative_pattern, text, re.IGNORECASE)]\n",
        "\n",
        "        positive_props = {match[0] for match in positive_matches}\n",
        "        negative_props = {match[0] for match in negative_matches}\n",
        "\n",
        "        contradictions = positive_props & negative_props\n",
        "        if contradictions:\n",
        "            violations.append(f\"Logical contradiction for propositions: {contradictions}\")\n",
        "            return (False, violations)\n",
        "\n",
        "        return (True, [])\n",
        "\n",
        "    def check_constraints(self, text: str, constraint_types: List[str] = None) -> Tuple[bool, List[str]]:\n",
        "        \"\"\"\n",
        "        Main constraint checking interface\n",
        "        \"\"\"\n",
        "        if constraint_types is None:\n",
        "            constraint_types = ['arithmetic', 'logical']\n",
        "\n",
        "        all_violations = []\n",
        "        is_consistent = True\n",
        "\n",
        "        if 'arithmetic' in constraint_types:\n",
        "            arith_consistent, arith_violations = self.check_arithmetic_consistency(text)\n",
        "            if not arith_consistent:\n",
        "                is_consistent = False\n",
        "                all_violations.extend(arith_violations)\n",
        "\n",
        "        if 'logical' in constraint_types:\n",
        "            logic_consistent, logic_violations = self.check_logical_consistency(text)\n",
        "            if not logic_consistent:\n",
        "                is_consistent = False\n",
        "                all_violations.extend(logic_violations)\n",
        "\n",
        "        return (is_consistent, all_violations)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGsM3j6xPFWa"
      },
      "source": [
        "### Test the Constraint Checker"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Czas8v00PFWb"
      },
      "source": [
        "## Phi-2 Integration with Constraint-Guided Beam Search\n",
        "\n",
        "Implementation of Algorithm 1 from the paper with:\n",
        "1. 4-bit quantized Phi-2 model loading\n",
        "2. Modified beam search with constraint verification\n",
        "3. Incremental constraint checking\n",
        "4. Early pruning for efficiency"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 621,
          "referenced_widgets": [
            "41c6f63a9a12465299ef657c76de712a",
            "d335974e04c542aaa34f87c84aa8d993",
            "6ef49856ad094b5f8791ae304f28517a",
            "fbae0fcb8c5e40f193126eaf4d7c10a5",
            "c810e4cb7d9a4e718e068a92da3ca646",
            "f26c2cdec2d34bbfbed7483217cda82a",
            "78031f376c574cb4b43e96daaa78d20c",
            "ea73073d21ae480dba188675b96b40af",
            "ae2ffd2fb1e34a71b5b9f32193564f4c",
            "2bc5633e2b4c429d8d82a9ca7fdbc0cb",
            "427d088dd1214ceb8d6601149a651a58",
            "cc8de695802a4b49b18a1ca34f81ac4e",
            "9a3b0ccfa39c42be838f2399fd869964",
            "7f15a685faf24c2098f43f63022787d6",
            "6994b02b89cd4035976f490933cab91b",
            "5294b8aeb7ef403ba156c861f7791b9a",
            "2b28a60e482b47d296ea0bd47aea1f16",
            "abe791bd589545949ea8418113bebad7",
            "16986080c59348b98ef7365ee0f4ee0d",
            "1b34caf216474ea9a05d627da293febd",
            "654340f272b64220920139b95367e651",
            "0decc8c28bef44b48d51c52d4b2ce126",
            "dcc3f05abd1244af91769ef86b574f8c",
            "d8e17a67f15940c2855e368459922b41",
            "1af95fa8464c4ec082cf3e332d40974c",
            "b44e00284e8d4574aa33103d891e000d",
            "2f28dfcf49f54efc8bd4f66a6efd33f1",
            "cf0dbd29edfd4160a57bdcc99e87dec2",
            "7d310da56de14fd2b0967731b2f75bf6",
            "5d3d29dfdf69435fb7609cb6463f9d59",
            "d7165a6569e2454e9208a025a317ed09",
            "18760d4d623c4ac8a90578ca1cbad942",
            "984da5e7e8494a259f70554f70e5a2e2",
            "fbed99506fc74aa5bc99b06455c57eaf",
            "0a95a940c3d54522b0ebffcbaedf9432",
            "32c7de961e9440698245749d461abc24",
            "a07d4ba902614e6a9c5d7488e3562193",
            "10eb528a20024200aca3cd6e4f254318",
            "af1e83686ece42d5b0edc3fcaab2c045",
            "9eb8182d090f47f99c5b2b4eba33889e",
            "4110a8f7c8044ba0ac47bf9659bc4e1c",
            "d2743e794dff481f8339d79aba401979",
            "46b0a1b5da1d4f7bb1e94281f2cefd82",
            "6517213a9ee645be92185f2e8f69a8aa",
            "d9a152b59b74450e9800e8eca5ba090e",
            "986cab9584924f8ea7131e91869f63f5",
            "a6aada517b3148d7a2882d9e27aa3efa",
            "2ee053f2d3644df8b1b65c6a9ce14179",
            "4e8c3f41a1db4b27a6a48c6f23a532a2",
            "10645983fe844037a43dd9f8b293555f",
            "f753287bc8ed4f85aaba9264cef02dfc",
            "d20ad39dddd14980b716a9f8556e1ba5",
            "a98f0cde5902440cbc044f4aa04b7f5e",
            "ecbf5cd5166c485c9cc1d4a08359e8f0",
            "7f034227fdda4666ac0013eaee6105c0",
            "960ce64a52bc48248341e0580bbdff99",
            "34efc3e9ee964707a07b59dd641e3111",
            "a51e02693a284bd393fc8b317522951b",
            "2daf9c7c8d244da38884b19fc02518ed",
            "e762176b50e941b192c57647aa9ee4a6",
            "6e8230a7425b4df8a99a1673196f53cb",
            "cc4121464182465687fbae9eea896603",
            "ac1754b9f1db407696f0a2b3ad3236f0",
            "2b20218f6c5b43ecb4f755b1bc92da19",
            "5375cdd831d547c39ec73e32c63ed9ce",
            "41b59805cf584152b3bfc4420f2b5341",
            "ed5f15fe48db4a888ab7ecad0291408b",
            "49b9bf53e5864c0fab06f4499211b4ff",
            "af99a79b950748419ca507f9231ed05a",
            "bf28857713e54cc19f015cf63acfdd08",
            "598e0e135dc14c76bcdbdcef67ce5923",
            "f74f09317ded43cab16940eea9d30910",
            "d26fb2dbdae145f68eec9c687993404d",
            "a975a1cdd37a4f8793ac04a0baf7bca8",
            "790519d1f9594959a57f554e19853b54",
            "66a7c3a02feb43b39679303460a32794",
            "21965554312043e3a4ed49b4e205548b",
            "f2a15e99d2704f2ca75b76754be9e99b",
            "00d3a19d30e4440d90a4f7a288ae4b6f",
            "27166843bf794eca99e8fdc649c88813",
            "0f71b95da478459da22fffae180ead59",
            "1ca24f3ec90f4460bbeea982eb611eae",
            "57587edca2754b37ad2b0d8cd2aedae2",
            "969ba50a425b4db6969882504c27ae83",
            "389396de633d485b81005980996292fd",
            "8efa7517a4354c46988f54387edfc108",
            "81824c6e88e54b2c896d41820127882a",
            "495ea37184bf4961967b7cd5125a7f54",
            "0821f4ede8b745ffa2787662b7481271",
            "51a3d18c4d0047a99b438fbc25937625",
            "93e2d773942b437e9bab0165619ebff8",
            "290f4b0bfdc747609c69fc42558ff5af",
            "3a80681a7fdc45d6b365dad442260764",
            "b5c2e345dfe448359c8e5f0eb0f3943e",
            "713d42f5c66648239635addbda5be4d1",
            "b833470034604620a1a002e28d0b2fe8",
            "8b225df8c2c84992bc65b150845c7551",
            "1dfb78527031455eae44e2ca72f51916",
            "4b695c765d8a4f208c582ce3e628f425",
            "4a6dcf11fda34bb38fda5e17a3885dca",
            "7d22319f20fc4e5ca24695685a54adf1",
            "2ee72aa6c9444b7a8a7ad9983154266a",
            "fae888177c89468482423e3ca129505d",
            "503b8728900c48e997cde01a129b01ae",
            "fb2d508e141f4adfb2025d5cb1cac362",
            "813af7a8abcf4727a17d03674b587bd5",
            "a118416a4a8d423491229f5f0eef2d9b",
            "825c7320ba0e4951b1908d1fa9e7e8aa",
            "da39b7297f75496680875610ee306473",
            "de43af758c72491ab48cabf86e6c9f59",
            "9103753176dc4534bbc5b0e5c41be90a",
            "5f08a4b1efc24069820375189ab1da84",
            "6f37d5eb1b084ee4a778abd96b3e4b3f",
            "b949d210ec644f1eb91d2b0785b1defb",
            "c7896440aa274be18a175d614873cb4e",
            "8b35a815f44c42d7ba5faae474e08fbe",
            "3661011b200a409cbfad5c5629d0caf1",
            "85f55f18a7704170993d174a5e6f7e2b",
            "e809fc68495c4223ba724b56761a2947",
            "d7acd9f16f684a47af7e0f3974849eef",
            "603aec3767814069bad4dfe51d64ac5c",
            "16138dac201144d6a251a0982834042d",
            "034f1801aa9f45b6880b3fe894f574ed",
            "e1bc25669c19425ca28a486407e765dd",
            "17e288b7f606431b94c09842f27e99a9",
            "5d9dde62eae64b8da08f316d7afc6704",
            "24153375c9f248179c2412a66340faed",
            "79cf3169b5bd42f2a0cfcd29dba62961",
            "bb252d81043c4b0cbf0aeea349ac5b2b",
            "03de4a84696541838cc13735cfb4ccaa",
            "6335962d43bf44a598193d1588b4acfd",
            "3b556b68227e478a993bc9f21467b064",
            "85738243289a40519ff650c7fa681838",
            "43a2e0aa93364780a97547df5ec6d0fd",
            "8a59464d64f44d35ba52414c42e8556f",
            "a878454371df4e5ea0e39736e6f72681",
            "1f750ef7ce294c668595531c6ed6f32c",
            "a35b0404f8f942fdaad309b433f97ae4",
            "bffbdfe5ba804ae686bc1521bc2a3592",
            "50d7caa9d7974d658b32e67f16b31592",
            "76f58a1bd61e4397892153ef90cea600",
            "b5c345b7e1b2434f85d0a383ba85a10a",
            "f7892f14ae8041deb014d1dad7d2b14b"
          ]
        },
        "id": "RyYK_Vv9PFWb",
        "outputId": "305e494e-2d3a-4ce0-c813-84df48b81035"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Phi-2 model with 4-bit quantization...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "41c6f63a9a12465299ef657c76de712a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cc8de695802a4b49b18a1ca34f81ac4e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dcc3f05abd1244af91769ef86b574f8c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fbed99506fc74aa5bc99b06455c57eaf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "added_tokens.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d9a152b59b74450e9800e8eca5ba090e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/99.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "960ce64a52bc48248341e0580bbdff99"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/735 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ed5f15fe48db4a888ab7ecad0291408b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`torch_dtype` is deprecated! Use `dtype` instead!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f2a15e99d2704f2ca75b76754be9e99b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0821f4ede8b745ffa2787662b7481271"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00002-of-00002.safetensors:   0%|          | 0.00/564M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4a6dcf11fda34bb38fda5e17a3885dca"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00001-of-00002.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9103753176dc4534bbc5b0e5c41be90a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "16138dac201144d6a251a0982834042d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "85738243289a40519ff650c7fa681838"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Model loaded successfully!\n",
            "  Model size: 1.78 GB\n"
          ]
        }
      ],
      "source": [
        "# load Phi-2 with 4-bit quantization\n",
        "print(\"Loading Phi-2 model with 4-bit quantization...\")\n",
        "\n",
        "quantization_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_compute_dtype=torch.float16,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_use_double_quant=True,\n",
        ")\n",
        "\n",
        "model_name = \"microsoft/phi-2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    quantization_config=quantization_config,\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True,\n",
        "    torch_dtype=torch.float16,\n",
        ")\n",
        "\n",
        "print(f\"✓ Model loaded successfully!\")\n",
        "print(f\"  Model size: {model.get_memory_footprint() / 1e9:.2f} GB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "EOQ3Q6-fPFWb"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class BeamState:\n",
        "    \"\"\"State for a single beam during search\"\"\"\n",
        "    sequence: List[int]  # token IDs\n",
        "    text: str  # decoded text\n",
        "    score: float  # log probability\n",
        "    violations: Set[str]  # accumulated constraint violations\n",
        "    is_finished: bool = False\n",
        "\n",
        "class ConstraintGuidedDecoder:\n",
        "    \"\"\"Modified beam search with constraint enforcement (Algorithm 1)\"\"\"\n",
        "\n",
        "    def __init__(self, model, tokenizer, constraint_checker, beam_width=4, lambda_weight=1.0):\n",
        "        self.model = model\n",
        "        self.tokenizer = tokenizer\n",
        "        self.checker = constraint_checker\n",
        "        self.beam_width = beam_width\n",
        "        self.lambda_weight = lambda_weight\n",
        "\n",
        "    def get_top_k_tokens(self, input_ids: torch.Tensor, k: int) -> List[Tuple[int, float]]:\n",
        "        \"\"\"\n",
        "        Get top-k next tokens with their log probabilities\n",
        "        \"\"\"\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model(input_ids)\n",
        "            logits = outputs.logits[:, -1, :]  # get logits for last position\n",
        "\n",
        "            #  softmax to get probabilities\n",
        "            probs = torch.nn.functional.softmax(logits, dim=-1)\n",
        "            log_probs = torch.log(probs)\n",
        "\n",
        "            #  top-k\n",
        "            top_log_probs, top_indices = torch.topk(log_probs, k, dim=-1)\n",
        "\n",
        "            # -> list of (token_id, log_prob) tuples\n",
        "            results = []\n",
        "            for idx, log_prob in zip(top_indices[0].cpu().tolist(), top_log_probs[0].cpu().tolist()):\n",
        "                results.append((idx, log_prob))\n",
        "\n",
        "            return results\n",
        "\n",
        "    def calculate_constraint_penalty(self, text: str, prev_violations: Set[str]) -> float:\n",
        "        \"\"\"\n",
        "        Calculate phi(y_t) from Equation 1\n",
        "        Returns: 0 if constraints satisfied, or -inf if new violations\n",
        "        \"\"\"\n",
        "        is_consistent, new_violations = self.checker.check_constraints(text)\n",
        "\n",
        "        # convert violations list to set\n",
        "        current_violations = set(new_violations)\n",
        "\n",
        "        # check if new violations (Eq. 2)\n",
        "        if not current_violations.issubset(prev_violations):\n",
        "            return float('-inf')  # new violations - prune beam\n",
        "\n",
        "        return 0.0  # No new violations\n",
        "\n",
        "    def generate(\n",
        "        self,\n",
        "        prompt: str,\n",
        "        max_new_tokens: int = 100,\n",
        "        constraint_types: List[str] = None,\n",
        "        temperature: float = 1.0,\n",
        "    ) -> Dict:\n",
        "        \"\"\"\n",
        "        Main constraint-guided generation (Algorithm 1)\n",
        "\n",
        "        Returns:\n",
        "            dict with 'text', 'score', 'violations', 'stats'\n",
        "        \"\"\"\n",
        "        start_time = time.time()\n",
        "\n",
        "        # initialiaze\n",
        "        input_ids = self.tokenizer.encode(prompt, return_tensors=\"pt\").to(self.model.device)\n",
        "        initial_state = BeamState(\n",
        "            sequence=input_ids[0].tolist(),\n",
        "            text=prompt,\n",
        "            score=0.0,\n",
        "            violations=set()\n",
        "        )\n",
        "\n",
        "        beams = [initial_state]\n",
        "\n",
        "        tokens_generated = 0\n",
        "        candidates_pruned = 0\n",
        "\n",
        "        # beam search loop\n",
        "        for step in range(max_new_tokens):\n",
        "            if all(beam.is_finished for beam in beams):\n",
        "                break\n",
        "\n",
        "            all_candidates = []\n",
        "\n",
        "            # expand each beam\n",
        "            for beam in beams:\n",
        "                if beam.is_finished:\n",
        "                    # keep finished beams, nothing else to do\n",
        "                    all_candidates.append(beam)\n",
        "                    continue\n",
        "\n",
        "                # get top 2k tokens for this beam\n",
        "                beam_input_ids = torch.tensor([beam.sequence]).to(self.model.device)\n",
        "                top_tokens = self.get_top_k_tokens(beam_input_ids, k=2 * self.beam_width)\n",
        "\n",
        "                # eval each token\n",
        "                for token_id, log_prob in top_tokens:\n",
        "                    # create new seq\n",
        "                    new_sequence = beam.sequence + [token_id]\n",
        "                    new_text = self.tokenizer.decode(new_sequence, skip_special_tokens=True)\n",
        "\n",
        "                    # check constraints incrementally\n",
        "                    constraint_penalty = self.calculate_constraint_penalty(\n",
        "                        new_text, beam.violations\n",
        "                    )\n",
        "\n",
        "                    # prune iff constraints violated (Eq. 1)\n",
        "                    if constraint_penalty == float('-inf'):\n",
        "                        candidates_pruned += 1\n",
        "                        continue\n",
        "\n",
        "                    # calc score w/ constraint penalty\n",
        "                    new_score = beam.score + log_prob + self.lambda_weight * constraint_penalty\n",
        "\n",
        "                    # check if sequence is finished\n",
        "                    is_finished = (token_id == self.tokenizer.eos_token_id)\n",
        "\n",
        "                    # gen new beam state\n",
        "                    new_beam = BeamState(\n",
        "                        sequence=new_sequence,\n",
        "                        text=new_text,\n",
        "                        score=new_score,\n",
        "                        violations=beam.violations.copy(),\n",
        "                        is_finished=is_finished\n",
        "                    )\n",
        "\n",
        "                    all_candidates.append(new_beam)\n",
        "\n",
        "            # get top-k candidates\n",
        "            all_candidates.sort(key=lambda x: x.score, reverse=True)\n",
        "            beams = all_candidates[:self.beam_width]\n",
        "\n",
        "            tokens_generated += 1\n",
        "\n",
        "        # return best complete sequence\n",
        "        best_beam = max(beams, key=lambda x: x.score)\n",
        "\n",
        "        end_time = time.time()\n",
        "\n",
        "        return {\n",
        "            'text': best_beam.text,\n",
        "            'score': best_beam.score,\n",
        "            'violations': list(best_beam.violations),\n",
        "            'stats': {\n",
        "                'tokens_generated': tokens_generated,\n",
        "                'candidates_pruned': candidates_pruned,\n",
        "                'time_seconds': end_time - start_time,\n",
        "                'final_beam_count': len(beams)\n",
        "            }\n",
        "        }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "og2BFywuPFWc"
      },
      "source": [
        "### Initialize the Constraint-Guided Decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "StZVvu1SPFWc",
        "outputId": "70458484-c2ba-419e-98ad-60867f0d4ec4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Constraint-Guided Decoder initialized!\n"
          ]
        }
      ],
      "source": [
        "# create decoder instance\n",
        "constraint_checker = ConstraintChecker()\n",
        "decoder = ConstraintGuidedDecoder(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    constraint_checker=constraint_checker,\n",
        "    beam_width=6,  # can reduce  this width to 2 if OOM\n",
        "    lambda_weight=1.0\n",
        ")\n",
        "\n",
        "print(\"✓ Constraint-Guided Decoder initialized!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhIpUkvqPFWc"
      },
      "source": [
        "## Testing and Validation\n",
        "\n",
        "Test the complete pipeline with arithmetic reasoning examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffrWitQWPFWc",
        "outputId": "0b095022-0ced-4e79-f19d-545ff549bf87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "TESTS\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "TEST 1: Basic Arithmetic Consistency\n",
            "================================================================================\n",
            "Setup: Give model x = 5, ask for 2x\n",
            "Expected: Should output 10 (2*5=10)\n",
            "Testing: Does constraint system prevent wrong answers?\n",
            "\n",
            "Running constrained generation...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- CONSTRAINED OUTPUT ---\n",
            "Full text: x = 5. Calculate 2x.\n",
            "Answer: 2x = (2 * 5) = 10.\n",
            "\n",
            "Exercise 2: Simplify the expression 3(\n",
            "\n",
            "Constraint violations: 0\n",
            "Candidates pruned: 10\n",
            "Generation time: 20.82s\n",
            "\n",
            "--- RESULT ---\n",
            "Contains '10': YES\n",
            "Status: PASS\n",
            "\n",
            "\n",
            "================================================================================\n",
            "TEST 2: Baseline vs Constrained Comparison\n",
            "================================================================================\n",
            "Setup: x = 7, y = 3, calculate x + y\n",
            "Expected: Both should output 10\n",
            "Testing: Does constraint add overhead? Does it help accuracy?\n",
            "\n",
            "Running BASELINE (standard beam search, no constraints)...\n",
            "\n",
            "--- BASELINE OUTPUT ---\n",
            "Full text: Given x = 7 and y = 3, what is x + y?\n",
            "Answer: x + y = 7 + 3 = 10\n",
            "\n",
            "Exercise 2: Solve the equation 2x - 5 =\n",
            "Constraint violations: 2\n",
            "  - Contradiction: y = 3.0 but later y = 7.0\n",
            "  - Arithmetic error: x + y should be 10.0 but text claims 7.0\n",
            "Contains '10': YES\n",
            "Generation time: 3.45s\n",
            "\n",
            "Running CONSTRAINED generation...\n",
            "\n",
            "--- CONSTRAINED OUTPUT ---\n",
            "Full text: Given x = 7 and y = 3, what is x + y?\n",
            "Answer: x + y = (7) + (3) = 10\n",
            "\n",
            "Exercise 2: Simplify the expression:\n",
            "Constraint violations: 0\n",
            "Contains '10': YES\n",
            "Candidates pruned: 56\n",
            "Generation time: 19.66s\n",
            "\n",
            "--- COMPARISON ---\n",
            "Baseline violations: 2\n",
            "Constrained violations: 0\n",
            "Time overhead: 16.21s (469.8% slower)\n",
            "IMPROVEMENT: Reduced 2 violation(s)\n",
            "\n",
            "\n",
            "================================================================================\n",
            "TEST 3: Preventing Contradictions\n",
            "================================================================================\n",
            "Setup: State a = 6, then ask model to calculate 2a\n",
            "Expected: Should NOT say things like '2a = 15' (would be wrong)\n",
            "Testing: Can we prevent the model from generating false arithmetic?\n",
            "\n",
            "Running constrained generation...\n",
            "\n",
            "--- CONSTRAINED OUTPUT ---\n",
            "Full text: We know that a = 6. Now calculate 2a.\n",
            "Solution: Since a = 6, we have 2a = (2)(6) = 12.\n",
            "\n",
            "\n",
            "Constraint violations: 0\n",
            "Candidates pruned: 10\n",
            "\n",
            "--- RESULT ---\n",
            "Expected answer (12): FOUND ✓\n",
            "No contradictions: YES ✓\n",
            "Status: PASS\n",
            "\n",
            "\n",
            "================================================================================\n",
            "TEST 4: Multi-Variable Arithmetic\n",
            "================================================================================\n",
            "Setup: m = 4, n = 5, calculate m * n\n",
            "Expected: Should output 20\n",
            "Testing: Can handle multiple variables correctly?\n",
            "\n",
            "--- CONSTRAINED OUTPUT ---\n",
            "Full text: Let m = 4 and n = 5. What is m * n?\n",
            "Answer: m * n = (4) * (5) = 20\n",
            "\n",
            "Exercise 2: Evaluate the following expression\n",
            "Violations: 0\n",
            "Contains '20': YES ✓\n",
            "Status: PASS\n",
            "\n",
            "\n",
            "================================================================================\n",
            "SUMMARY\n",
            "================================================================================\n",
            "PASS: Test 1: Basic arithmetic (x=5, 2x=?)\n",
            "PASS: Test 2: Reduced violations vs baseline\n",
            "PASS: Test 3: Contradiction prevention (a=6, 2a=?)\n",
            "PASS: Test 4: Multi-variable (m=4,n=5,m*n=?)\n",
            "\n",
            "Overall: 4/4 tests passed\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "import time\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"TESTS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# ========================================================================\n",
        "# TEST 1: Basic Arithmetic Consistency\n",
        "# ========================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"TEST 1: Basic Arithmetic Consistency\")\n",
        "print(\"=\"*80)\n",
        "print(\"Setup: Give model x = 5, ask for 2x\")\n",
        "print(\"Expected: Should output 10 (2*5=10)\")\n",
        "print(\"Testing: Does constraint system prevent wrong answers?\\n\")\n",
        "\n",
        "prompt1 = \"x = 5. Calculate 2x.\\nAnswer: 2x =\"\n",
        "\n",
        "# Run constrained generation\n",
        "print(\"Running constrained generation...\")\n",
        "start = time.time()\n",
        "constrained_result = decoder.generate(\n",
        "    prompt=prompt1,\n",
        "    max_new_tokens=20,\n",
        "    constraint_types=['arithmetic']\n",
        ")\n",
        "constrained_time = time.time() - start\n",
        "\n",
        "print(f\"\\n--- CONSTRAINED OUTPUT ---\")\n",
        "print(f\"Full text: {constrained_result['text']}\")\n",
        "print(f\"\\nConstraint violations: {len(constrained_result['violations'])}\")\n",
        "if constrained_result['violations']:\n",
        "    for v in constrained_result['violations']:\n",
        "        print(f\"  - {v}\")\n",
        "print(f\"Candidates pruned: {constrained_result['stats']['candidates_pruned']}\")\n",
        "print(f\"Generation time: {constrained_time:.2f}s\")\n",
        "\n",
        "# Check if answer is correct\n",
        "constrained_correct = \"10\" in constrained_result['text']\n",
        "\n",
        "print(f\"\\n--- RESULT ---\")\n",
        "print(f\"Contains '10': {'YES' if constrained_correct else 'NO'}\")\n",
        "print(f\"Status: {'PASS' if constrained_correct and len(constrained_result['violations'])==0 else 'FAIL'}\")\n",
        "\n",
        "# ========================================================================\n",
        "# TEST 2: Baseline Comparison (No Constraints)\n",
        "# ========================================================================\n",
        "print(\"\\n\\n\" + \"=\"*80)\n",
        "print(\"TEST 2: Baseline vs Constrained Comparison\")\n",
        "print(\"=\"*80)\n",
        "print(\"Setup: x = 7, y = 3, calculate x + y\")\n",
        "print(\"Expected: Both should output 10\")\n",
        "print(\"Testing: Does constraint add overhead? Does it help accuracy?\\n\")\n",
        "\n",
        "prompt2 = \"Given x = 7 and y = 3, what is x + y?\\nAnswer: x + y =\"\n",
        "\n",
        "# Baseline (no constraints)\n",
        "print(\"Running BASELINE (standard beam search, no constraints)...\")\n",
        "input_ids = tokenizer.encode(prompt2, return_tensors=\"pt\").to(model.device)\n",
        "start = time.time()\n",
        "baseline_output = model.generate(\n",
        "    input_ids,\n",
        "    max_new_tokens=20,\n",
        "    num_beams=4,\n",
        "    early_stopping=True,\n",
        "    pad_token_id=tokenizer.eos_token_id,\n",
        "    do_sample=False\n",
        ")\n",
        "baseline_time = time.time() - start\n",
        "baseline_text = tokenizer.decode(baseline_output[0], skip_special_tokens=True)\n",
        "\n",
        "# Check baseline for violations\n",
        "baseline_consistent, baseline_viols = constraint_checker.check_constraints(baseline_text, ['arithmetic'])\n",
        "\n",
        "print(f\"\\n--- BASELINE OUTPUT ---\")\n",
        "print(f\"Full text: {baseline_text}\")\n",
        "print(f\"Constraint violations: {len(baseline_viols)}\")\n",
        "if baseline_viols:\n",
        "    for v in baseline_viols:\n",
        "        print(f\"  - {v}\")\n",
        "print(f\"Contains '10': {'YES' if '10' in baseline_text else 'NO'}\")\n",
        "print(f\"Generation time: {baseline_time:.2f}s\")\n",
        "\n",
        "# Constrained\n",
        "print(\"\\nRunning CONSTRAINED generation...\")\n",
        "start = time.time()\n",
        "constrained_result2 = decoder.generate(\n",
        "    prompt=prompt2,\n",
        "    max_new_tokens=20,\n",
        "    constraint_types=['arithmetic']\n",
        ")\n",
        "constrained_time2 = time.time() - start\n",
        "\n",
        "print(f\"\\n--- CONSTRAINED OUTPUT ---\")\n",
        "print(f\"Full text: {constrained_result2['text']}\")\n",
        "print(f\"Constraint violations: {len(constrained_result2['violations'])}\")\n",
        "if constrained_result2['violations']:\n",
        "    for v in constrained_result2['violations']:\n",
        "        print(f\"  - {v}\")\n",
        "print(f\"Contains '10': {'YES' if '10' in constrained_result2['text'] else 'NO'}\")\n",
        "print(f\"Candidates pruned: {constrained_result2['stats']['candidates_pruned']}\")\n",
        "print(f\"Generation time: {constrained_time2:.2f}s\")\n",
        "\n",
        "# Comparison\n",
        "print(f\"\\n--- COMPARISON ---\")\n",
        "print(f\"Baseline violations: {len(baseline_viols)}\")\n",
        "print(f\"Constrained violations: {len(constrained_result2['violations'])}\")\n",
        "print(f\"Time overhead: {constrained_time2 - baseline_time:.2f}s ({((constrained_time2/baseline_time - 1)*100):.1f}% slower)\")\n",
        "\n",
        "improvement = len(baseline_viols) - len(constrained_result2['violations'])\n",
        "if improvement > 0:\n",
        "    print(f\"IMPROVEMENT: Reduced {improvement} violation(s)\")\n",
        "elif improvement < 0:\n",
        "    print(f\"WORSE: Added {abs(improvement)} violation(s)\")\n",
        "else:\n",
        "    print(f\"= SAME: No difference in violations\")\n",
        "\n",
        "# ========================================================================\n",
        "# TEST 3: Contradiction Prevention\n",
        "# ========================================================================\n",
        "print(\"\\n\\n\" + \"=\"*80)\n",
        "print(\"TEST 3: Preventing Contradictions\")\n",
        "print(\"=\"*80)\n",
        "print(\"Setup: State a = 6, then ask model to calculate 2a\")\n",
        "print(\"Expected: Should NOT say things like '2a = 15' (would be wrong)\")\n",
        "print(\"Testing: Can we prevent the model from generating false arithmetic?\\n\")\n",
        "\n",
        "prompt3 = \"We know that a = 6. Now calculate 2a.\\nSolution: Since a = 6, we have 2a =\"\n",
        "\n",
        "print(\"Running constrained generation...\")\n",
        "constrained_result3 = decoder.generate(\n",
        "    prompt=prompt3,\n",
        "    max_new_tokens=25,\n",
        "    constraint_types=['arithmetic']\n",
        ")\n",
        "\n",
        "print(f\"\\n--- CONSTRAINED OUTPUT ---\")\n",
        "print(f\"Full text: {constrained_result3['text']}\")\n",
        "print(f\"\\nConstraint violations: {len(constrained_result3['violations'])}\")\n",
        "if constrained_result3['violations']:\n",
        "    for v in constrained_result3['violations']:\n",
        "        print(f\"  - {v}\")\n",
        "print(f\"Candidates pruned: {constrained_result3['stats']['candidates_pruned']}\")\n",
        "\n",
        "# Check correctness (2*6 = 12)\n",
        "correct_answer = \"12\" in constrained_result3['text']\n",
        "\n",
        "print(f\"\\n--- RESULT ---\")\n",
        "print(f\"Expected answer (12): {'FOUND ✓' if correct_answer else 'NOT FOUND ✗'}\")\n",
        "print(f\"No contradictions: {'YES ✓' if len(constrained_result3['violations'])==0 else 'NO ✗'}\")\n",
        "print(f\"Status: {'PASS' if correct_answer and len(constrained_result3['violations'])==0 else 'FAIL'}\")\n",
        "\n",
        "# ========================================================================\n",
        "# TEST 4: Multi-Variable Consistency\n",
        "# ========================================================================\n",
        "print(\"\\n\\n\" + \"=\"*80)\n",
        "print(\"TEST 4: Multi-Variable Arithmetic\")\n",
        "print(\"=\"*80)\n",
        "print(\"Setup: m = 4, n = 5, calculate m * n\")\n",
        "print(\"Expected: Should output 20\")\n",
        "print(\"Testing: Can handle multiple variables correctly?\\n\")\n",
        "\n",
        "prompt4 = \"Let m = 4 and n = 5. What is m * n?\\nAnswer: m * n =\"\n",
        "\n",
        "constrained_result4 = decoder.generate(\n",
        "    prompt=prompt4,\n",
        "    max_new_tokens=20,\n",
        "    constraint_types=['arithmetic']\n",
        ")\n",
        "\n",
        "print(f\"--- CONSTRAINED OUTPUT ---\")\n",
        "print(f\"Full text: {constrained_result4['text']}\")\n",
        "print(f\"Violations: {len(constrained_result4['violations'])}\")\n",
        "print(f\"Contains '20': {'YES ✓' if '20' in constrained_result4['text'] else 'NO ✗'}\")\n",
        "print(f\"Status: {'PASS' if '20' in constrained_result4['text'] else 'FAIL'}\")\n",
        "\n",
        "# ========================================================================\n",
        "# SUMMARY\n",
        "# ========================================================================\n",
        "print(\"\\n\\n\" + \"=\"*80)\n",
        "print(\"SUMMARY\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "tests = [\n",
        "    (\"Test 1: Basic arithmetic (x=5, 2x=?)\",\n",
        "     len(constrained_result['violations']) == 0),\n",
        "    (\"Test 2: Reduced violations vs baseline\",\n",
        "     len(constrained_result2['violations']) <= len(baseline_viols)),\n",
        "    (\"Test 3: Contradiction prevention (a=6, 2a=?)\",\n",
        "     len(constrained_result3['violations']) == 0),\n",
        "    (\"Test 4: Multi-variable (m=4,n=5,m*n=?)\",\n",
        "     len(constrained_result4['violations']) == 0)\n",
        "]\n",
        "\n",
        "passed = sum(1 for _, result in tests if result)\n",
        "\n",
        "for test_name, result in tests:\n",
        "    status = \"PASS\" if result else \"FAIL\"\n",
        "    print(f\"{status}: {test_name}\")\n",
        "\n",
        "print(f\"\\nOverall: {passed}/{len(tests)} tests passed\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yoc4HISKPFWd"
      },
      "source": [
        "## Utility Functions and Analysis Tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OERhxM_XPFWd",
        "outputId": "db298dce-ff52-46e4-a2a6-746dd70ea07c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Evaluation utilities ready!\n",
            "  Sample dataset: 3 problems\n"
          ]
        }
      ],
      "source": [
        "def evaluate_on_dataset(decoder, problems: List[Dict], max_new_tokens=100):\n",
        "    \"\"\"\n",
        "    Evaluate decoder on a list of problems\n",
        "    Each problem should have 'prompt' and optionally 'expected_answer'\n",
        "    \"\"\"\n",
        "    results = []\n",
        "\n",
        "    for i, problem in enumerate(problems):\n",
        "        print(f\"\\nProblem {i+1}/{len(problems)}\")\n",
        "        print(f\"Prompt: {problem['prompt'][:100]}...\")\n",
        "\n",
        "        result = decoder.generate(\n",
        "            prompt=problem['prompt'],\n",
        "            max_new_tokens=max_new_tokens,\n",
        "            constraint_types=['arithmetic']\n",
        "        )\n",
        "\n",
        "        results.append({\n",
        "            'problem': problem,\n",
        "            'output': result['text'],\n",
        "            'violations': result['violations'],\n",
        "            'stats': result['stats']\n",
        "        })\n",
        "\n",
        "        print(f\"Violations: {len(result['violations'])}\")\n",
        "        print(f\"Time: {result['stats']['time_seconds']:.2f}s\")\n",
        "\n",
        "    return results\n",
        "\n",
        "def analyze_results(results: List[Dict]):\n",
        "    \"\"\"\n",
        "    Analyze evaluation results\n",
        "    \"\"\"\n",
        "    total = len(results)\n",
        "    violation_free = sum(1 for r in results if len(r['violations']) == 0)\n",
        "    avg_time = np.mean([r['stats']['time_seconds'] for r in results])\n",
        "    avg_pruned = np.mean([r['stats']['candidates_pruned'] for r in results])\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"EVALUATION SUMMARY\")\n",
        "    print(\"=\"*80)\n",
        "    print(f\"Total problems: {total}\")\n",
        "    print(f\"Violation-free outputs: {violation_free} ({100*violation_free/total:.1f}%)\")\n",
        "    print(f\"Average generation time: {avg_time:.2f}s\")\n",
        "    print(f\"Average candidates pruned: {avg_pruned:.1f}\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "# Example dataset for testing\n",
        "sample_problems = [\n",
        "    {\n",
        "        'prompt': \"Question: If x = 7, what is 3x?\\nAnswer:\",\n",
        "        'expected': 21\n",
        "    },\n",
        "    {\n",
        "        'prompt': \"Question: Sarah has 15 cookies. She eats 3. How many are left?\\nAnswer:\",\n",
        "        'expected': 12\n",
        "    },\n",
        "    {\n",
        "        'prompt': \"Question: A rectangle has length 5 and width 3. What is its area?\\nAnswer:\",\n",
        "        'expected': 15\n",
        "    },\n",
        "]\n",
        "\n",
        "print(\"✓ Evaluation utilities ready!\")\n",
        "print(f\"  Sample dataset: {len(sample_problems)} problems\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GvXGn07ZPFWd"
      },
      "source": [
        "##  Evaluation on Sample Problems"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Aj6fpQr_PFWd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b814062-da98-4040-fb73-6cae3ae0d3c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Problem 1/3\n",
            "Prompt: Question: If x = 7, what is 3x?\n",
            "Answer:...\n",
            "Violations: 0\n",
            "Time: 22.05s\n",
            "\n",
            "Problem 2/3\n",
            "Prompt: Question: Sarah has 15 cookies. She eats 3. How many are left?\n",
            "Answer:...\n",
            "Violations: 0\n",
            "Time: 22.72s\n",
            "\n",
            "Problem 3/3\n",
            "Prompt: Question: A rectangle has length 5 and width 3. What is its area?\n",
            "Answer:...\n",
            "Violations: 0\n",
            "Time: 22.18s\n",
            "\n",
            "================================================================================\n",
            "EVALUATION SUMMARY\n",
            "================================================================================\n",
            "Total problems: 3\n",
            "Violation-free outputs: 3 (100.0%)\n",
            "Average generation time: 22.31s\n",
            "Average candidates pruned: 45.0\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        " results = evaluate_on_dataset(decoder, sample_problems, max_new_tokens=50)\n",
        " analyze_results(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBRQ7Zc0PFWd"
      },
      "source": [
        "## Optimization and Ablation Studies\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhjAYmD4PFWd",
        "outputId": "d966de04-fa19-45df-a225-59da86557303"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ablation study functions ready!\n"
          ]
        }
      ],
      "source": [
        "def ablation_beam_width(prompt: str, beam_widths=[2, 4, 8]):\n",
        "    \"\"\"\n",
        "    Test impact of beam width on performance\n",
        "    \"\"\"\n",
        "    results = {}\n",
        "\n",
        "    for width in beam_widths:\n",
        "        print(f\"\\nTesting beam width = {width}\")\n",
        "\n",
        "        decoder_temp = ConstraintGuidedDecoder(\n",
        "            model=model,\n",
        "            tokenizer=tokenizer,\n",
        "            constraint_checker=ConstraintChecker(),\n",
        "            beam_width=width,\n",
        "            lambda_weight=1.0\n",
        "        )\n",
        "\n",
        "        result = decoder_temp.generate(prompt, max_new_tokens=50)\n",
        "        results[width] = result\n",
        "\n",
        "        print(f\"  Time: {result['stats']['time_seconds']:.2f}s\")\n",
        "        print(f\"  Violations: {len(result['violations'])}\")\n",
        "        print(f\"  Pruned: {result['stats']['candidates_pruned']}\")\n",
        "\n",
        "    return results\n",
        "\n",
        "def ablation_lambda_weight(prompt: str, lambda_values=[0.5, 1.0, 2.0]):\n",
        "    \"\"\"\n",
        "    Test impact of constraint strictness (lambda)\n",
        "    \"\"\"\n",
        "    results = {}\n",
        "\n",
        "    for lambda_val in lambda_values:\n",
        "        print(f\"\\nTesting lambda = {lambda_val}\")\n",
        "\n",
        "        decoder_temp = ConstraintGuidedDecoder(\n",
        "            model=model,\n",
        "            tokenizer=tokenizer,\n",
        "            constraint_checker=ConstraintChecker(),\n",
        "            beam_width=4,\n",
        "            lambda_weight=lambda_val\n",
        "        )\n",
        "\n",
        "        result = decoder_temp.generate(prompt, max_new_tokens=50)\n",
        "        results[lambda_val] = result\n",
        "\n",
        "        print(f\"  Score: {result['score']:.4f}\")\n",
        "        print(f\"  Violations: {len(result['violations'])}\")\n",
        "\n",
        "    return results\n",
        "\n",
        "print(\"ablation study functions ready!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CeETE4NJPFWd"
      },
      "source": [
        "## Save and Export Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-OizSGDPFWd",
        "outputId": "7f00b4ce-458a-4254-b0ad-20ab85532bcd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Save functions ready!\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "def save_results(results: Dict, filename: str = None):\n",
        "    \"\"\"\n",
        "    Save experimental results to JSON\n",
        "    \"\"\"\n",
        "    if filename is None:\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        filename = f\"results_{timestamp}.json\"\n",
        "\n",
        "    # convert sets to lists for JSON serialization\n",
        "    serializable_results = {}\n",
        "    for key, value in results.items():\n",
        "        if isinstance(value, dict):\n",
        "            serializable_results[key] = {\n",
        "                k: list(v) if isinstance(v, set) else v\n",
        "                for k, v in value.items()\n",
        "            }\n",
        "        else:\n",
        "            serializable_results[key] = value\n",
        "\n",
        "    with open(filename, 'w') as f:\n",
        "        json.dump(serializable_results, f, indent=2)\n",
        "\n",
        "    print(f\"Results saved to {filename}\")\n",
        "\n",
        "print(\"Save functions ready!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWjOWxXLPFWe"
      },
      "source": [
        "## Interactive Testing Cell\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQQ4GA9IPFWe",
        "outputId": "0fd7a671-f198-43a6-fea3-4077ec1df930"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Text:\n",
            "Question: If a train travels 60 miles in 2 hours, what is its speed?\n",
            "Answer: Let me calculate this. To find the speed, we need to divide the distance traveled by the time taken. In this case, the train traveled 60 miles in 2 hours. So, the speed would be 60 miles divided by 2 hours, which equals 30 miles per hour.\n",
            "\n",
            "Violations: []\n",
            "Generation time: 29.22s\n",
            "Candidates pruned: 0\n"
          ]
        }
      ],
      "source": [
        "# feel free to change this prompt and run to test\n",
        "custom_prompt = \"\"\"Question: If a train travels 60 miles in 2 hours, what is its speed?\n",
        "Answer: Let me calculate this.\"\"\"\n",
        "\n",
        "custom_result = decoder.generate(\n",
        "    prompt=custom_prompt,\n",
        "    max_new_tokens=50,\n",
        "    constraint_types=['arithmetic']\n",
        ")\n",
        "\n",
        "print(\"Generated Text:\")\n",
        "print(custom_result['text'])\n",
        "print(f\"\\nViolations: {custom_result['violations']}\")\n",
        "print(f\"Generation time: {custom_result['stats']['time_seconds']:.2f}s\")\n",
        "print(f\"Candidates pruned: {custom_result['stats']['candidates_pruned']}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation\n",
        "\n",
        "import pandas as pd\n",
        "import json\n",
        "import time\n",
        "\n",
        "test_cases = [\n",
        "    {\"prompt\": \"x = 5. Calculate 2x.\\nAnswer: 2x =\", \"expected\": \"10\", \"type\": \"multiplication\"},\n",
        "    {\"prompt\": \"x = 7 and y = 3. What is x + y?\\nAnswer:\", \"expected\": \"10\", \"type\": \"addition\"},\n",
        "    {\"prompt\": \"a = 6. What is 2a?\\nAnswer: 2a =\", \"expected\": \"12\", \"type\": \"multiplication\"},\n",
        "    {\"prompt\": \"m = 4 and n = 5. What is m * n?\\nAnswer:\", \"expected\": \"20\", \"type\": \"multiplication\"},\n",
        "    {\"prompt\": \"p = 10. What is p + 5?\\nAnswer:\", \"expected\": \"15\", \"type\": \"addition\"},\n",
        "    {\"prompt\": \"x = 8. Calculate 3x.\\nAnswer: 3x =\", \"expected\": \"24\", \"type\": \"multiplication\"},\n",
        "    {\"prompt\": \"a = 2 and b = 9. What is a + b?\\nAnswer:\", \"expected\": \"11\", \"type\": \"addition\"},\n",
        "    {\"prompt\": \"n = 7. What is 4n?\\nAnswer: 4n =\", \"expected\": \"28\", \"type\": \"multiplication\"},\n",
        "    {\"prompt\": \"x = 12. What is x + 8?\\nAnswer:\", \"expected\": \"20\", \"type\": \"addition\"},\n",
        "    {\"prompt\": \"y = 3. Calculate 5y.\\nAnswer: 5y =\", \"expected\": \"15\", \"type\": \"multiplication\"},\n",
        "    {\"prompt\": \"a = 6 and b = 6. What is a + b?\\nAnswer:\", \"expected\": \"12\", \"type\": \"addition\"},\n",
        "    {\"prompt\": \"k = 9. What is 2k?\\nAnswer: 2k =\", \"expected\": \"18\", \"type\": \"multiplication\"},\n",
        "    {\"prompt\": \"x = 4 and y = 7. Calculate x + y.\\nAnswer:\", \"expected\": \"11\", \"type\": \"addition\"},\n",
        "    {\"prompt\": \"m = 5. What is 6m?\\nAnswer: 6m =\", \"expected\": \"30\", \"type\": \"multiplication\"},\n",
        "    {\"prompt\": \"a = 15 and b = 5. What is a + b?\\nAnswer:\", \"expected\": \"20\", \"type\": \"addition\"},\n",
        "]\n",
        "\n",
        "results = []\n",
        "\n",
        "for i, test in enumerate(test_cases):\n",
        "    print(f\"Running test {i+1}/{len(test_cases)}: {test['type']}\")\n",
        "\n",
        "    # Baseline\n",
        "    input_ids = tokenizer.encode(test[\"prompt\"], return_tensors=\"pt\").to(model.device)\n",
        "    start = time.time()\n",
        "    baseline_out = model.generate(\n",
        "        input_ids,\n",
        "        max_new_tokens=25,\n",
        "        num_beams=5,\n",
        "        early_stopping=True,\n",
        "        pad_token_id=tokenizer.eos_token_id,\n",
        "        do_sample=False\n",
        "    )\n",
        "    baseline_time = time.time() - start\n",
        "    baseline_text = tokenizer.decode(baseline_out[0], skip_special_tokens=True)\n",
        "    baseline_consistent, baseline_violations = constraint_checker.check_constraints(baseline_text)\n",
        "\n",
        "    # Constrained\n",
        "    constraint_checker.clear()\n",
        "    start = time.time()\n",
        "    constrained_result = decoder.generate(\n",
        "        prompt=test[\"prompt\"],\n",
        "        max_new_tokens=25,\n",
        "        constraint_types=['arithmetic']\n",
        "    )\n",
        "    constrained_time = time.time() - start\n",
        "\n",
        "    results.append({\n",
        "        \"id\": i + 1,\n",
        "        \"type\": test[\"type\"],\n",
        "        \"expected\": test[\"expected\"],\n",
        "        \"baseline_correct\": test[\"expected\"] in baseline_text,\n",
        "        \"baseline_violations\": len(baseline_violations),\n",
        "        \"baseline_time\": round(baseline_time, 2),\n",
        "        \"constrained_correct\": test[\"expected\"] in constrained_result[\"text\"],\n",
        "        \"constrained_violations\": len(constrained_result[\"violations\"]),\n",
        "        \"constrained_time\": round(constrained_time, 2),\n",
        "        \"pruned\": constrained_result[\"stats\"][\"candidates_pruned\"]\n",
        "    })\n",
        "\n",
        "df = pd.DataFrame(results)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"RESULTS\")\n",
        "print(\"=\"*70)\n",
        "print(df.to_string(index=False))\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"AGGREGATE\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Total tests: {len(results)}\")\n",
        "print(f\"Baseline correct: {sum(r['baseline_correct'] for r in results)}/{len(results)}\")\n",
        "print(f\"Constrained correct: {sum(r['constrained_correct'] for r in results)}/{len(results)}\")\n",
        "print(f\"Baseline total violations: {sum(r['baseline_violations'] for r in results)}\")\n",
        "print(f\"Constrained total violations: {sum(r['constrained_violations'] for r in results)}\")\n",
        "print(f\"Avg baseline time: {sum(r['baseline_time'] for r in results)/len(results):.2f}s\")\n",
        "print(f\"Avg constrained time: {sum(r['constrained_time'] for r in results)/len(results):.2f}s\")\n",
        "print(f\"Avg candidates pruned: {sum(r['pruned'] for r in results)/len(results):.1f}\")\n",
        "\n",
        "output = {\n",
        "    \"config\": {\n",
        "        \"model\": \"microsoft/phi-2\",\n",
        "        \"quantization\": \"4-bit NF4\",\n",
        "        \"beam_width\": 5,\n",
        "        \"lambda\": 1.0\n",
        "    },\n",
        "    \"results\": results,\n",
        "    \"summary\": {\n",
        "        \"total\": len(results),\n",
        "        \"baseline_correct\": sum(r['baseline_correct'] for r in results),\n",
        "        \"constrained_correct\": sum(r['constrained_correct'] for r in results),\n",
        "        \"baseline_violations\": sum(r['baseline_violations'] for r in results),\n",
        "        \"constrained_violations\": sum(r['constrained_violations'] for r in results)\n",
        "    }\n",
        "}\n",
        "\n",
        "with open(\"evaluation_results.json\", \"w\") as f:\n",
        "    json.dump(output, f, indent=2)\n",
        "\n",
        "print(\"\\nSaved to evaluation_results.json\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lnhDPecQHVaV",
        "outputId": "35fd90c5-3076-44bb-acf8-71a9026d9e29"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running test 1/15: multiplication\n",
            "Running test 2/15: addition\n",
            "Running test 3/15: multiplication\n",
            "Running test 4/15: multiplication\n",
            "Running test 5/15: addition\n",
            "Running test 6/15: multiplication\n",
            "Running test 7/15: addition\n",
            "Running test 8/15: multiplication\n",
            "Running test 9/15: addition\n",
            "Running test 10/15: multiplication\n",
            "Running test 11/15: addition\n",
            "Running test 12/15: multiplication\n",
            "Running test 13/15: addition\n",
            "Running test 14/15: multiplication\n",
            "Running test 15/15: addition\n",
            "\n",
            "======================================================================\n",
            "RESULTS\n",
            "======================================================================\n",
            " id           type expected  baseline_correct  baseline_violations  baseline_time  constrained_correct  constrained_violations  constrained_time  pruned\n",
            "  1 multiplication       10              True                    2           2.14                 True                       0             17.93      10\n",
            "  2       addition       10              True                    1           2.46                 True                       0             12.76      41\n",
            "  3 multiplication       12              True                    2           2.11                 True                       0             12.47      10\n",
            "  4 multiplication       20              True                    1           2.11                 True                       0             12.73      10\n",
            "  5       addition       15              True                    0           2.11                 True                       0             10.83      10\n",
            "  6 multiplication       24              True                    2           2.27                 True                       0             12.24      11\n",
            "  7       addition       11              True                    1           2.42                 True                       0             12.90      21\n",
            "  8 multiplication       28              True                    2           2.09                 True                       0             12.69      10\n",
            "  9       addition       20              True                    0           4.77                 True                       0             19.21      11\n",
            " 10 multiplication       15              True                    2           3.58                 True                       0             19.31      10\n",
            " 11       addition       12              True                    1           2.07                 True                       0             12.68      21\n",
            " 12 multiplication       18              True                    2           2.12                 True                       0             12.46      10\n",
            " 13       addition       11              True                    2           2.09                 True                       0             12.92      32\n",
            " 14 multiplication       30              True                    2           2.53                False                       0             12.42      32\n",
            " 15       addition       20              True                    2           2.06                 True                       0             12.64      55\n",
            "\n",
            "======================================================================\n",
            "AGGREGATE\n",
            "======================================================================\n",
            "Total tests: 15\n",
            "Baseline correct: 15/15\n",
            "Constrained correct: 14/15\n",
            "Baseline total violations: 22\n",
            "Constrained total violations: 0\n",
            "Avg baseline time: 2.46s\n",
            "Avg constrained time: 13.75s\n",
            "Avg candidates pruned: 19.6\n",
            "\n",
            "Saved to evaluation_results.json\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}